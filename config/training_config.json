{
  "default": {
    "total_episodes": 1000,
    "total_episodes_normal": "1000",
    "max_turns_per_episode": 5,
    "max_steps_per_turn": 50,
    "callback_params": {
      "checkpoint_save_freq": 50000,
      "checkpoint_name_prefix": "ppo_checkpoint",
      "eval_deterministic": true,
      "eval_render": false,
      "n_eval_episodes": 5
    },
    "observation_params": {
      "obs_size": 295,
      "perception_radius": 25,
      "max_nearby_units": 10,
      "max_valid_targets": 5,
      "justification": "R=25 covers MOVE(12)+CHARGE(12)+ENEMY_OFFSET(1). 295 floats = asymmetric obs (72 ally + 138 enemy + 35 targets)"
    },
    "exploration": {
      "initial_epsilon": 0.3,
      "final_epsilon": 0.05,
      "exploration_fraction": 0.3 
    },
    "model_params": {
      "policy": "MlpPolicy",
      "learning_rate": 0.001,
      "n_steps": 2048,
      "batch_size": 128,
      "n_epochs": 10,
      "gamma": 0.95,
      "gae_lambda": 0.95,
      "clip_range": 0.2,
      "clip_range_vf": null,
      "normalize_advantage": true,
      "ent_coef": 0.05,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "target_kl": null,
      "tensorboard_log": "./tensorboard/",
      "policy_kwargs": {
        "net_arch": [256, 256]
      },
      "verbose": 0
    }
  },
  "debug": {
    "total_episodes": 50,
    "max_turns_per_episode": 5,
    "max_steps_per_turn": 50,
    "callback_params": {
      "checkpoint_save_freq": 5000,
      "checkpoint_name_prefix": "ppo_debug_checkpoint",
      "eval_deterministic": true,
      "eval_render": false,
      "n_eval_episodes": 2
    },
    "observation_params": {
      "obs_size": 295,
      "perception_radius": 25,
      "max_nearby_units": 10,
      "max_valid_targets": 5,
      "justification": "R=25 covers MOVE(12)+CHARGE(12)+ENEMY_OFFSET(1). 295 floats = asymmetric obs (72 ally + 138 enemy + 35 targets)"
    },
    "model_params": {
      "policy": "MlpPolicy",
      "learning_rate": 0.0001,
      "n_steps": 512,
      "batch_size": 128,
      "n_epochs": 4,
      "gamma": 0.95,
      "gae_lambda": 0.9,
      "clip_range": 0.2,
      "ent_coef": 0.1,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "tensorboard_log": "./tensorboard/",
      "policy_kwargs": {
        "net_arch": [128, 128]
      },
      "verbose": 0
    }
  },
  "phase1": {
    "observation_params": {
      "obs_size": 295,
      "perception_radius": 25,
      "max_nearby_units": 10,
      "max_valid_targets": 5,
      "justification": "Phase 1: Learn 'shooting is good' - any target, high exploration. 295 floats = asymmetric obs"
    },
    "model_params": {
      "policy": "MlpPolicy",
      "learning_rate": 0.001,
      "n_steps": 512,
      "batch_size": 128,
      "n_epochs": 4,
      "gamma": 0.95,
      "gae_lambda": 0.9,
      "clip_range": 0.2,
      "ent_coef": 0.10,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "tensorboard_log": "./tensorboard/",
      "policy_kwargs": {
        "net_arch": [128, 128]
      },
      "verbose": 0
    },
    "total_episodes": 100,
    "total_episodes_normal_value": "100",
    "max_turns_per_episode": 5,
    "max_steps_per_turn": 50,
    "callback_params": {
      "checkpoint_save_freq": 2500,
      "checkpoint_name_prefix": "ppo_curriculum_p1",
      "eval_deterministic": true,
      "eval_render": false,
      "n_eval_episodes": 5
    }
  },
  "phase2": {
    "observation_params": {
      "obs_size": 295,
      "perception_radius": 25,
      "max_nearby_units": 10,
      "max_valid_targets": 5,
      "justification": "Phase 2: Learn target priorities - kill weak targets first. 295 floats = asymmetric obs"
    },
    "model_params": {
      "policy": "MlpPolicy",
      "learning_rate": 0.0005,
      "n_steps": 1024,
      "batch_size": 128,
      "n_epochs": 6,
      "gamma": 0.95,
      "gae_lambda": 0.95,
      "clip_range": 0.2,
      "ent_coef": 0.05,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "tensorboard_log": "./tensorboard/",
      "policy_kwargs": {
        "net_arch": [256, 256]
      },
      "verbose": 0
    },
    "total_episodes": 500,
    "max_turns_per_episode": 5,
    "max_steps_per_turn": 250,
    "callback_params": {
      "checkpoint_save_freq": 10000,
      "checkpoint_name_prefix": "ppo_curriculum_p2",
      "eval_deterministic": true,
      "eval_render": false,
      "n_eval_episodes": 10
    }
  },
  "phase3": {
    "observation_params": {
      "obs_size": 295,
      "perception_radius": 25,
      "max_nearby_units": 10,
      "max_valid_targets": 5,
      "justification": "Phase 3: Learn full tactical priorities with RewardMapper. 295 floats = asymmetric obs"
    },
    "model_params": {
      "policy": "MlpPolicy",
      "learning_rate": 0.0001,
      "n_steps": 2048,
      "batch_size": 128,
      "n_epochs": 10,
      "gamma": 0.95,
      "gae_lambda": 0.95,
      "clip_range": 0.2,
      "ent_coef": 0.03,
      "vf_coef": 0.5,
      "max_grad_norm": 0.5,
      "tensorboard_log": "./tensorboard/",
      "policy_kwargs": {
        "net_arch": [256, 256]
      },
      "verbose": 0
    },
    "total_episodes": 3000,
    "total_episodes_normal_value": "1000",
    "max_turns_per_episode": 5,
    "max_steps_per_turn": 250,
    "callback_params": {
      "checkpoint_save_freq": 20000,
      "checkpoint_name_prefix": "ppo_curriculum_p3",
      "eval_deterministic": true,
      "eval_render": false,
      "n_eval_episodes": 10
    }
  }
}